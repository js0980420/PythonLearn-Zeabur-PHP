# Zeabur éƒ¨ç½²é…ç½® - å–®ä¸€æœå‹™æ¶æ§‹
name: pythonlearn-collaboration

services:
  # ä¸»è¦æ‡‰ç”¨æœå‹™ - åŒ…å« Web + WebSocket
  web:
    # ä½¿ç”¨ Dockerfile æ§‹å»º
    dockerfile: Dockerfile.simple
    
    # ç«¯å£é…ç½® - Zeabur æœƒè‡ªå‹•è™•ç† HTTPS
    ports:
      - 8080  # ä¸»è¦ HTTP ç«¯å£
    
    # ç’°å¢ƒè®Šæ•¸
    envs:
      ENVIRONMENT: production
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      OPENAI_MODEL: gpt-3.5-turbo
      MAX_CONCURRENT_USERS: 50
      MAX_ROOMS: 20
    
    # å¥åº·æª¢æŸ¥
    healthcheck:
      path: /health.php
      interval: 30s
      timeout: 10s
    
    # é‡å•Ÿç­–ç•¥
    restart: unless-stopped

# éƒ¨ç½²é…ç½®
deploy:
  auto: true
  
  # ç’°å¢ƒè®Šæ•¸
  envs:
    optional:
      - OPENAI_API_KEY

# ğŸ” æ—¥èªŒé…ç½®
logging:
  driver: json-file
  options:
    max-size: "50m"
    max-file: "2"

# ğŸŒ ç¶²è·¯é…ç½®
networks:
  default:
    driver: bridge

# ğŸ“Š ç›£æ§é…ç½®
monitoring:
  enabled: true
  metrics:
    - name: http_requests_total
      type: counter
      help: "Total HTTP requests"
    
    - name: websocket_connections
      type: gauge
      help: "Active WebSocket connections"
    
    - name: caddy_requests_total
      type: counter
      help: "Total Caddy proxy requests"
    
    - name: ai_requests_total
      type: counter
      help: "Total AI assistant requests"
    
    - name: python_executions_total
      type: counter
      help: "Total Python code executions"

# ğŸ” å¯†é‘°ç®¡ç†
secrets:
  openai-api-key:
    external: true
    name: OPENAI_API_KEY

# å·é…ç½®
volumes:
  mysql_data:
    driver: local

# å¥åº·æª¢æŸ¥é…ç½®
healthcheck:
  web:
    path: /health.php
    interval: 30s
    timeout: 10s
    
  caddy:
    port: 80
    interval: 30s
    timeout: 10s

# ç’°å¢ƒè®Šæ•¸é…ç½®
env:
  # OpenAI API å¯†é‘°ï¼ˆéœ€è¦åœ¨ Zeabur æ§åˆ¶å°è¨­ç½®ï¼‰
  OPENAI_API_KEY:
    type: secret
    
  # åŸŸåï¼ˆZeabur è‡ªå‹•è¨­ç½®ï¼‰
  ZEABUR_DOMAIN:
    type: auto 